{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-rmToKKjbFi"
      },
      "source": [
        "# Examen de la práctica 2 de APR, grupo 4CO21, 10 de enero de 2024\n",
        "# Turno 1: de 19h a 19.45h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob-vhjD6jbFj"
      },
      "source": [
        "## El conjunto de datos caltech-101\n",
        "\n",
        "Caltech-101 consta de imágenes de objetos de 101 clases, más una clase \"cajón de sastre\". Cada imagen está etiquetada con un único objeto. Cada clase contiene entre 40 y 800 imágenes aproximadamente, con alrededor de 9.000 imágenes en total. Las imágenes son de tamaños variables, de anchos y altos típicamente entre 200 y 300 píxeles. A continuación se carga este conjunto de datos mediante la librería tensorflow_datasets y se divide en una parte para entrenamiento (train_data), otra para validación (val_data) y otra para test (test_data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FKYlS8UPkPPA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "train_data, val_data, test_data = tfds.load('caltech101', split=['train[:80%]', 'train[80%:]', 'test'], as_supervised=True)\n",
        "train_size=len(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK1CjRfGjbFk"
      },
      "source": [
        "## Ejercicio\n",
        "\n",
        "Como hicimos en las sesiones 3 y 4 de la práctica, haz un fine-tuning (ajuste fino) de una red Keras pre-entrenada con ImageNet que clasifique el test de caltech-101 con la máxima precisión posible, preferiblemente superior al 80%."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALM2sA3WkVjB",
        "outputId": "e7f31912-68d1-47a7-8949-35e32f5b94ed"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "img_size = (299, 299)\n",
        "num_classes = 102\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, img_size)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = preprocess_input(image)\n",
        "    label = tf.one_hot(label, num_classes)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "E2PjperTj21S"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.map(preprocess)\n",
        "val_data = val_data.map(preprocess)\n",
        "test_data = test_data.map(preprocess)"
      ],
      "metadata": {
        "id": "SkejxhdtkErk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.efficientnet import EfficientNetB0\n",
        "\n",
        "model = EfficientNetB0(input_shape=img_size + (3,),include_top=False, weights='imagenet')"
      ],
      "metadata": {
        "id": "i5ol6KUVkKAO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=model.input, outputs=output)"
      ],
      "metadata": {
        "id": "WJ-jGdqFkNOw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "opt=Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=opt,\n",
        "            metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WrgpzQ9rkclD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\n",
        "checkpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "epochs=10\n",
        "batch_size=32\n",
        "train_data= train_data.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "val_data = val_data.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "history = model.fit(train_data,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=val_data,\n",
        "                    callbacks=[reduce_lr,checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCMb0G73kgcV",
        "outputId": "835c0bed-54c9-4c49-f6f8-473f9dc4e1db"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "77/77 [==============================] - ETA: 0s - loss: 2.0975 - accuracy: 0.5764\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87255, saving model to best_model.h5\n",
            "77/77 [==============================] - 25s 170ms/step - loss: 2.0975 - accuracy: 0.5764 - val_loss: 0.4615 - val_accuracy: 0.8725 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "77/77 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.9048\n",
            "Epoch 2: val_accuracy improved from 0.87255 to 0.90850, saving model to best_model.h5\n",
            "77/77 [==============================] - 10s 133ms/step - loss: 0.3425 - accuracy: 0.9048 - val_loss: 0.3554 - val_accuracy: 0.9085 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "77/77 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9473\n",
            "Epoch 3: val_accuracy did not improve from 0.90850\n",
            "77/77 [==============================] - 10s 125ms/step - loss: 0.1896 - accuracy: 0.9473 - val_loss: 0.3538 - val_accuracy: 0.9085 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "77/77 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9726\n",
            "Epoch 4: val_accuracy improved from 0.90850 to 0.91993, saving model to best_model.h5\n",
            "77/77 [==============================] - 10s 132ms/step - loss: 0.1156 - accuracy: 0.9726 - val_loss: 0.3234 - val_accuracy: 0.9199 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "77/77 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9853\n",
            "Epoch 5: val_accuracy did not improve from 0.91993\n",
            "77/77 [==============================] - 10s 127ms/step - loss: 0.0684 - accuracy: 0.9853 - val_loss: 0.3304 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "77/77 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9910\n",
            "Epoch 6: val_accuracy improved from 0.91993 to 0.93301, saving model to best_model.h5\n",
            "77/77 [==============================] - 10s 135ms/step - loss: 0.0471 - accuracy: 0.9910 - val_loss: 0.3045 - val_accuracy: 0.9330 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "77/77 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9873\n",
            "Epoch 7: val_accuracy did not improve from 0.93301\n",
            "77/77 [==============================] - 10s 128ms/step - loss: 0.0462 - accuracy: 0.9873 - val_loss: 0.3283 - val_accuracy: 0.9216 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "77/77 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9890\n",
            "Epoch 8: val_accuracy did not improve from 0.93301\n",
            "77/77 [==============================] - 10s 129ms/step - loss: 0.0432 - accuracy: 0.9890 - val_loss: 0.3409 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "77/77 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9943\n",
            "Epoch 9: val_accuracy did not improve from 0.93301\n",
            "77/77 [==============================] - 10s 130ms/step - loss: 0.0275 - accuracy: 0.9943 - val_loss: 0.3167 - val_accuracy: 0.9265 - lr: 2.0000e-04\n",
            "Epoch 10/10\n",
            "77/77 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9975\n",
            "Epoch 10: val_accuracy did not improve from 0.93301\n",
            "77/77 [==============================] - 11s 138ms/step - loss: 0.0198 - accuracy: 0.9975 - val_loss: 0.3104 - val_accuracy: 0.9297 - lr: 2.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('best_model.h5')\n",
        "test_dataset_batched = test_data.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "score = model.evaluate(test_dataset_batched, verbose=0)\n",
        "print(f'Test loss: {score[0]*100:.2f}')\n",
        "print(f'Test accuracy: {score[1]*100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e29YOKakjlg",
        "outputId": "872405fd-b9b4-4bbc-97ca-b707a686a7ae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 41.52\n",
            "Test accuracy: 88.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2W8aQ4lgsAxY"
      },
      "execution_count": 34,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}